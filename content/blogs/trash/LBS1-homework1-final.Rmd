---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: HOMEWORK 1
draft: false
image: 
keywords: ""
slug: hmw
title: Data Analytics Potpourri
---

---
title: 'Data Visualization Challenges'
author: "Awashti Palak, Kaikati Jeffrey, Laffitte Jose, Opre Valeria, Wang Hanyu, Zhang Jasmine "
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
  pdf_document:
    toc: yes
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(fivethirtyeight)
library(here)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(rvest) # to scrape wikipedia page
```


# Challenge 1: Replicating a chart

The purpose of this challenge is to reproduce a plot using `dplyr` and `ggplot2` skills. 

Read the  article [The Racial Factor: There's 77 Counties Which Are Deep Blue But Also Low-Vaxx. Guess What They Have In Common?](https://acasignups.net/21/07/18/racial-factor-theres-77-counties-which-are-deep-blue-also-low-vaxx-guess-what-they-have) and have a look at the attached figure.

1. To get vaccination by county, we will use [data from the CDC](https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-County/8xkx-amqh)
2. You need to get [County Presidential Election Returns 2000-2020](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)
3. Finally, you also need an estimate of the [population of each county](https://www.ers.usda.gov/webdocs/DataFiles/48747/PopulationEstimates.csv?v=2232)
 

```{r, cache=TRUE}

# Download CDC vaccination by county
cdc_url <- "https://data.cdc.gov/api/views/8xkx-amqh/rows.csv?accessType=DOWNLOAD"
vaccinations <- vroom(cdc_url) %>% 
  janitor::clean_names() %>% 
  filter(fips != "UNK") # remove counties that have an unknown (UNK) FIPS code

# Download County Presidential Election Returns
# https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ
election2020_results <- vroom(here::here("data", "countypres_2000-2020.csv")) %>% 
  janitor::clean_names() %>% 
  
  # just keep the results for the 2020 election
  filter(year == "2020") %>% 
  
  # change original name county_fips to fips, to be consistent with the other two files
  rename (fips = county_fips)

# Download county population data
population_url <- "https://www.ers.usda.gov/webdocs/DataFiles/48747/PopulationEstimates.csv?v=2232"
population <- vroom(population_url) %>% 
  janitor::clean_names() %>% 
  
  # select the latest data, namely 2019
  select(fips = fip_stxt, pop_estimate_2019) %>% 
  
  # pad FIPS codes with leading zeros, so they are always made up of 5 characters
  mutate(fips = stringi::stri_pad_left(fips, width=5, pad = "0"))

```


```{r}
#we are going to take a look at the data first and then we will have to merge the data

population_vaccinations <- left_join(population, vaccinations, by="fips")


pve <- left_join(population_vaccinations, election2020_results, by="fips")
# we will group pve by county
```

```{r}

pve %>%
  filter(date =="08/03/2021") %>%
  filter(candidate == "DONALD J TRUMP") %>%
  filter(series_complete_pop_pct > 1) %>%
  mutate(percentage_trump= candidatevotes/totalvotes*100) %>%
  filter(percentage_trump > 1) %>%
  ggplot(aes(x=percentage_trump, y=series_complete_pop_pct)) +
  geom_point(aes(size = pop_estimate_2019))+
  scale_size_continuous(range = c(0.01, 5))+
  xlim(0,100)+
  ylim(0,100)+
  labs(title = "COVID-19 VACCINATION LEVELS OUT OF TOTAL POPULATION BY COUNTY",
        subtitle = "Most states on FULLY vaccinated only;CA, GA, IA, MI & TX based on total doses administered",
         x = "2020 Trump Vote %", 
         y = "Percentage of Total Population Vaccinated",
         caption = "Centers for Disease Control, COVID Act NOW, state health depts")

pve

```


# Challenge 2: Opinion polls for the 2021 German elections

The Guardian newspaper has an [election poll tracker for the upcoming German election](https://www.theguardian.com/world/2021/aug/20/german-election-poll-tracker-who-will-be-the-next-chancellor).
The list of the opinion polls since Jan 2021 can be found at [Wikipedia](https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election) and the task is to reproduce the graph similar to the one produced by the Guardian. 


The following code will scrape the wikipedia page and import the table in a dataframe.


```{r, scrape_wikipedia_polling_data, warnings= FALSE, message=FALSE}
url <- "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election"
# https://www.economist.com/graphic-detail/who-will-succeed-angela-merkel
# https://www.theguardian.com/world/2021/jun/21/german-election-poll-tracker-who-will-be-the-next-chancellor


# get tables that exist on wikipedia page 
tables <- url %>% 
  read_html() %>% 
  html_nodes(css="table")


# parse HTML tables into a dataframe called polls 
# Use purr::map() to create a list of all tables in URL
polls <- map(tables, . %>% 
             html_table(fill=TRUE)%>% 
             janitor::clean_names())


# list of opinion polls
german_election_polls <- polls[[1]] %>% # the first table on the page contains the list of all opinions polls
  slice(2:(n()-1)) %>%  # drop the first row, as it contains again the variable names and last row that contains 2017 results
  mutate(
         # polls are shown to run from-to, e.g. 9-13 Aug 2021. We keep the last date, 13 Aug here, as the poll date
         # and we extract it by picking the last 11 characters from that field
         end_date = str_sub(fieldwork_date, -11),
         
         # end_date is still a string, so we convert it into a date object using lubridate::dmy()
         end_date = dmy(end_date),
         
         # we also get the month and week number from the date, if we want to do analysis by month- week, etc.
         month = month(end_date),
         week = isoweek(end_date)
         )
```



```{r}
german_election_polls %>%
  select(end_date,union, grune, spd, af_d, linke, fdp)%>%
  ggplot(aes(x=end_date, y= union))+
  geom_point()+
  geom_point(data=german_election_polls, aes(x=end_date, y= grune, color= "Green")) +
  geom_point(data=german_election_polls, aes(x=end_date, y= spd, color= "Red")) +
  geom_point(data=german_election_polls, aes(x=end_date, y= af_d, color= "Blue")) +
  geom_point(data=german_election_polls, aes(x=end_date, y= linke, color= "Purple")) +
  geom_point(data=german_election_polls, aes(x=end_date, y= fdp, color= "Yellow"))
 
german_election_polls %>%
  select(polling_firm, end_date,union, grune, spd, af_d, linke, fdp) %>%
  ggplot(aes(x=end_date, y=grune))+
  geom_point(color = "green")+
  geom_point(data = german_election_polls, aes(x=end_date, y=spd,color = "red"))+
  geom_point(data = german_election_polls, aes(x=end_date, y=af_d,color = "blue"))+
  geom_point(data = german_election_polls, aes(x=end_date, y=linke,color = "purple"))+
  geom_point(data = german_election_polls, aes(x=end_date, y=fdp,color = "yellow"))+
  geom_point(data = german_election_polls, aes(x=end_date, y=union))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=grune,color = "green", method="lm"))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=spd,color = "red", method="lm"))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=af_d,color = "blue", method="lm"))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=linke,color = "purple", method="lm"))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=fdp,color = "yellow", method="lm"))+
  geom_smooth(data = german_election_polls, aes(x=end_date, y=union, method="lm"))

```

```{r}
library(zoo)

rolling_dataset<- german_election_polls %>%
      select(polling_firm, end_date,week,union, grune, spd, af_d, linke, fdp) %>%
      arrange(desc(-week))%>%
      dplyr::mutate(rolling_spd = zoo::rollmean(spd, k = 14, fill = NA)) %>%
      dplyr::mutate(rolling_union = zoo::rollmean(union, k = 14, fill = NA)) %>%
      dplyr::mutate(rolling_grune = zoo::rollmean(grune, k = 14, fill = NA)) %>%
      dplyr::mutate(rolling_af_d = zoo::rollmean(af_d, k = 14, fill = NA)) %>%
      dplyr::mutate(rolling_linke = zoo::rollmean(linke, k = 14, fill = NA)) %>%
      dplyr::mutate(rolling_fdp = zoo::rollmean(fdp, k = 14, fill = NA))  
  
rolling_dataset %>%
  ggplot(aes(x=end_date, y=rolling_spd))+
      geom_line(color = "red")+
      geom_point(data = german_election_polls, aes(x=end_date, y=spd,color = "red"))+
      geom_line(data = rolling_dataset, aes(x=end_date, y=rolling_union))+
      geom_point(data = german_election_polls, aes(x=end_date, y=union))+
      geom_line(data = rolling_dataset, aes(x=end_date, y=rolling_grune, color = "green"))+
      geom_point(data = german_election_polls, aes(x=end_date, y=grune, color= "green"))+
      geom_line(data = rolling_dataset, aes(x=end_date, y=rolling_af_d, color = "blue"))+
      geom_point(data = german_election_polls, aes(x=end_date, y=af_d, color ="blue"))+
      geom_line(data = rolling_dataset, aes(x=end_date, y=rolling_linke, color = "purple"))+
      geom_point(data = german_election_polls, aes(x=end_date, y=linke, color ="purple"))+
      geom_line(data = rolling_dataset, aes(x=end_date, y=rolling_fdp, color = "yellow"))+
      geom_point(data = german_election_polls, aes(x=end_date, y=fdp, color ="yellow"))+
      labs(title = "German election poll tracker: who will be the next chancellor?",
        subtitle = "Find out who is leading the polling to succeed Angela Merkel as chancellor of Germany",
         x = "Date", 
         y = "Rolling average percentage",
         caption = "Source: wahirecht.de")
```






